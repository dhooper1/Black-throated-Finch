# Black-throated Finch Genomics
Data and code associated with population genomic study of the black-throated finch
# Recent divergence and microgeographic genetic structure in an endangered Australian songbird: the southern black-throated finch
The following is an overview of analyses and code used in Hooper et al. to examine genetic differentiation, spatial genetic structure, and demographic history in the northern black-throated finch *Poephila atropygialis* and the endangered southern black-throated finch *Poephila cincta*.

Software and programs used in this pipeline:
- [Stacks](https://catchenlab.life.illinois.edu/stacks/) (v2.59)
- [cutadapt](https://cutadapt.readthedocs.io/en/stable/) (v1.18)
- [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) (v0.39)
- [bwa](https://bio-bwa.sourceforge.net/) (v0.7.17)
- [samtools/bcftools](http://samtools.github.io/bcftools/bcftools.html)
- [STITCH](https://github.com/rwdavies/STITCH) (v1.6.6)
- [GATK](https://gatk.broadinstitute.org/hc/en-us) (v4.4)
- [RepeatModeler](https://github.com/Dfam-consortium/RepeatModeler)
- [vcftools](https://vcftools.sourceforge.net) (v0.1.16)
- [plink](https://www.cog-genomics.org/plink/1.9/) (v1.09)
- [fastStructure](https://rajanil.github.io/fastStructure/) (v1.0)
- [FEEMS](https://github.com/NovembreLab/feems)
- [ParseVCF_private.pl](https://github.com/ehshogren/MyzomelaPopulationGenomics/blob/main/ParseVCF_private.pl)
- [KING](https://www.kingrelatedness.com) (v2.3.1)
- [RAxML](https://github.com/stamatak/standard-RAxML) (v8.2.4)
- [vcf2phylip](https://github.com/edgardomortiz/vcf2phylip)
- [PSMC](https://github.com/lh3/psmc)
  - [vcfutils.pl](https://github.com/lh3/samtools/blob/master/bcftools/vcfutils.pl)
- [fastsimcoal27](https://cmpg.unibe.ch/software/fastsimcoal27/) (v2.7)
- [R](https://www.r-project.org) (v4.2.1)

## Contents

## raw read processing, aligment, and variant calling [WGS data]
The black-throated finch and long-tailed finch linked-read and short read WGS data used in this project was first generated by [Singhal et al. 2015](https://doi.org/10.1126/science.aad0843), [McDiarmid et al. 2024](https://doi.org/10.1111/mec.17374), and [Hooper et al. 2024](https://doi.org/10.1016/j.cub.2024.10.019). A full step-by-step pipeline for processing this data from raw reads to high-confidence genotype calls is described in detail [here](https://github.com/dhooper1/Long-tailed-Finch).

## raw read processing and aligment [ddRAD data]
We demultiplexed raw sequencing data using the process_radtags function in [Stacks](https://catchenlab.life.illinois.edu/stacks/) (v2.59). We only kept reads that passed default Stacks quality filters, the Illumina quality filter, contained both an intact SbfI and MspI RAD site, contained one of the unique barcodes with one mismatch allowance, and did not contain Illumina indexing adapters. All reads that passed these quality filters were then trimmed at their 3’ end to the length of the shortest sequence (i.e., 147 bp) using [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) (v0.39). Read data was mapped to the zebra finch reference genome (GCF_003957565.2) using [bwa](https://bio-bwa.sourceforge.net/) mem (v0.7.17). 

Example demultiplexing script for paired-end fastq data:
```
READ1="KAL01_CKDL210007123-1a_HFVLJCCX2_L4_1.fq"
READ2="KAL01_CKDL210007123-1a_HFVLJCCX2_L4_2.fq"
BARCODES="BTF_240_2021_Index01.txt"
OUT_DIR="/mendel-nas1/dhooper/BTFs/ddRAD/demux"

./process_radtags -1 ${READ1} -2 ${READ2} -b ${BARCODES} -o ${OUT_DIR} --renz_1 sbfI --renz_2 mspI -r -c -q -E phred33 --inline_null -i fastq --adapter_1 GATCGGAAGAGCACACGTCTGAACTCCAGTCACATCACGATCTCGTATGCCGTCTTCTGCTTG --adapter_mm 1 --filter_illumina --barcode_dist_2 1
```

Example read quality filtering script for demux'd paired-end fastq data:
```
cd /mendel-nas1/dhooper/BTFs/ddRAD/demux

cat ddRAD.sample.list | while read LINE; do
  java -jar /programs/trimmomatic/trimmomatic-0.39.jar PE ${LINE}.1.fq ${LINE}.2.fq ${LINE}.R1.trimmed.fq ${LINE}.R1.trimmed.unpaired.fq ${LINE}.R2.trimmed.fq ${LINE}.R2.trimmed.unpaired.fq ILLUMINACLIP:/pathto/TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:40;
done
```

Example mapping script for demux'd and quality filtered paired-end fastq data:
```
cd /mendel-nas1/dhooper/BTFs/ddRAD/demux

REF="/mendel-nas1/dhooper/reference/GCF_003957565.2_bTaeGut1.4.fasta"

cat ddRAD.sample.list | while read LINE; do
  bwa mem -M -t 8 ${REF} ${LINE}.R1.trimmed.fq ${LINE}.R2.trimmed.fq -R "@RG\tID:"$LINE"\tSM:"$LINE"\tLB:"$LINE"\tPL:Illumina.HiSeqX.2x150" | samtools view -bh > ${LINE}.PE.unsorted.bam;
  samtools sort -@ 20 -l 9 -T ${LINE}.tmpsort -o ${LINE}.PE.sorted.bam ${LINE}.PE.unsorted.bam;
  rm ${LINE}.PE.unsorted.bam;
  picard MarkDuplicates I=${LINE}.PE.sorted.bam O=${LINE}.PE.mkdup.bam M=${LINE}.mkdup.metrics CREATE_INDEX=TRUE VALIDATION_STRINGENCY=LENIENT;
  rm ${LINE}.PE.sorted.bam;
  echo "Finished mapping, sorting, and marking duplicates for sample: '$LINE'";
done
```

## variant discovery and genotyping [ddRAD data]
Genotyping samples with ddRAD data was performed in accordance with [GATK](https://gatk.broadinstitute.org/hc/en-us) (v4.4) Best Practices. An initial set of variants were called for each sample for each chromosome using HaplotypeCaller in GVCF mode, GVCF output from all samples were then combined by chromosome using CombineGVCFs, and joint genotyping was performed using GenotypeGVCFs.

Use GATK HaplotypeCaller to generate GVCF files for chromosome "chr1" for each sample:
```
REF="/mendel-nas1/dhooper/reference/GCF_003957565.2_bTaeGut1.4.fasta"
INPUT_DIR="/mendel-nas1/dhooper/BTFs/ddRAD/BAMs"
OUT_DIR="/mendel-nas1/dhooper/BTFs/ddRAD/VCFs"

## Run GATK HaplotypeCaller on chr1 for all samples
cat ddRAD.sample.list | while read LINE; do
  java -Xmx5g -jar /programs/bin/GATK/GenomeAnalysisTK.jar -T HaplotypeCaller -R ${REF} -L chr1 -I ${INPUT_DIR}/${LINE}.PE.mkdup.bam --emitRefConfidence GVCF -nct 8 -nt 1 -o ${OUT_DIR}/${LINE}.chr1.g.vcf;
done
```

Use GATK CombineGVCFs to combine all GVCF files for each chromosome:
```
REF="/mendel-nas1/dhooper/reference/GCF_003957565.2_bTaeGut1.4.fasta"

cd /mendel-nas1/dhooper/BTFs/ddRAD/VCFs

## Create list files of GVCF output for each chromosome
cat chrom.list | while read LINE; do
  ls *.${LINE}.g.vcf > all.samples.${LINE}.list;
done

## Run GATK CombineGVCFs
cat chrom.list | while read LINE; do
  java -Xmx75g -jar /programs/bin/GATK/GenomeAnalysisTK.jar -T CombineGVCFs -R ${REF} --variant all.samples.${LINE}.list -o BTFs.LTFs.${LINE}.g.vcf.gz;
done
```

Use GATK GenotypeGVCFs to perform join genotyping and output an initial set of raw SNP/INDEL variants ready for filtering:
```
REF="/mendel-nas1/dhooper/reference/GCF_003957565.2_bTaeGut1.4.fasta"

cd /mendel-nas1/dhooper/BTFs/ddRAD/VCFs

## Run GATK GenotypeGVCFs
cat chrom.list | while read LINE; do
  java -Xmx75g -jar /programs/bin/GATK/GenomeAnalysisTK.jar -T GenotypeGVCFs -R ${REF} -nt 16 --variant BTFs.LTFs.${LINE}.g.vcf.gz -o BTFs.LTFs.${LINE}.raw_variants.vcf.gz;
done
```

Perform hard quality filtering on the initial set of raw SNP/INDEL variants to produce a set of high-quality SNP variants:
```
REF="/mendel-nas1/dhooper/reference/GCF_003957565.2_bTaeGut1.4.fasta"
DATE="220418"

cd /mendel-nas1/dhooper/BTFs/ddRAD/VCFs

## Run GATK SelectVariants
cat chrom.list | while read LINE; do
  java -Xmx75g -jar /programs/bin/GATK/GenomeAnalysisTK.jar -T SelectVariants -R ${REF} -V BTFs.LTFs.${LINE}.raw_variants.vcf.gz -selectType SNP -o BTFs.LTFs.${LINE}.raw_snps.vcf.gz;
done

## Apply hard SNP quality filters
cat chrom.list | while read LINE; do
  java -Xmx75g -jar /programs/bin/GATK/GenomeAnalysisTK.jar -T VariantFiltration -R ${REF} -V BTFs.LTFs.${LINE}.raw_snps.vcf.gz --filterExpression "QD < 2.0 || FS > 60.0 || MQ < 40.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0" --filterName "hard_snp_filter" -o BTFs.LTFs.${LINE}.hq_snps.vcf.gz;
done

## Merge high-quality SNP data by chromosome into a single genome-wide VCF file
ls BTFs.LTFs.*.hq_snps.vcf.gz > VCF.list

bcftools concat -f VCF.list -a -D -Oz -o ${DATE}.BTFs.LTFs.whole_genome.hq_snps.vcf.gz
bcftools index ${DATE}.BTFs.LTFs.whole_genome.hq_snps.vcf.gz

```

## population structure, genetic differentiation, and summary statistics

### principal component analysis (PCA)
We performed PCA with [plink](https://www.cog-genomics.org/plink/1.9/) (v1.09) using the full dataset and sequential subsets of the full dataset. First, using both black-throated finch and long-tailed finch samples. Second, only using samples from the two black-throated finch subspecies. Third, only using samples from the endangered black-throated finch subspecies *cincta*. For the WGS dataset, we removed SNPs <1 kb apart, with a minor allele frequency less than 0.05, and genotyped in less than 0.95 of samples. For the ddRAD dataset, we removed singleton sites and SNPs <1 kb apart.

Example script for performing the PCA analyses shown in Figure 3:
```
## Use PLINK to perform PCA for cincta samples using ddRAD dataset

cd /mendel-nas1/dhooper/BTFs/ddRAD/

out_dir="/mendel-nas1/dhooper/BTFs/ddRAD/PCA"

## Convert VCF to BED, AF and randomly filter sites, and perform PCA
plink --allow-extra-chr --chr-set 40 --out ${out_dir}/ddRAD.btfs_ltfs.no_captives.mm85.AF --make-bed --vcf ddRAD.btfs_ltfs.no_captives.mm85.AF.vcf.gz

## Perform PCA with 1kb SNP distance filter, singletons removed, and SNPs with data in <85% of samples removed
plink --bfile ${out_dir}/ddRAD.btfs_ltfs.no_captives.mm85.AF --allow-extra-chr --chr-set 40 --keep cincta.all.pop --geno 0.15 --mac 2 --bp-space 1000 --pca 10 header tabs --allow-no-sex --out ${out_dir}/ddRAD.cincta.all.mm85.mac2.1kb_thin.pca1-10
plink --bfile ${out_dir}/ddRAD.btfs_ltfs.no_captives.mm85.AF --allow-extra-chr --chr-set 40 --keep cincta.minus_GB.pop --geno 0.15 --mac 2 --bp-space 1000 --pca 10 header tabs --allow-no-sex --out ${out_dir}/ddRAD.cincta.minus_GB.mm85.mac2.1kb_thin.pca1-10
plink --bfile ${out_dir}/ddRAD.btfs_ltfs.no_captives.mm85.AF --allow-extra-chr --chr-set 40 --keep cincta.minus_GB_SC.pop --geno 0.15 --mac 2 --bp-space 1000 --pca 10 header tabs --allow-no-sex --out ${out_dir}/ddRAD.cincta.minus_GB_SC.mm85.mac2.1kb_thin.pca1-10
rm ${out_dir}/*nosex
```

See R script plot.PCA.cincta.R above for details about plotting the PCA results in the panels of Figure 3D.

### fastStructure
Genotype data for black-throated finches was prepared by removing SNPs found in linkage disequilibrium (i.e., r2 > 0.2) in 100 kb windows and 10 kb steps using [plink](https://www.cog-genomics.org/plink/1.9/) (v1.09). We then ran [fastStructure](https://rajanil.github.io/fastStructure/) (v1.0) with ten cross-validation tests and values of K ranging from 2 to 5. The optimal model complexity was determined using the chooseK.py function of fastStructure. We restricted this analysis to the ddRAD dataset due to the greater breadth (i.e., sampled populations) and depth (i.e., sampled individuals) of coverage compared to the WGS dataset.

Example script for generating input genotype set and running fastStructure at a range of values of K
```
cd /mendel-nas1/dhooper/BTFs/ddRAD/

VCF="220418.BTFs.LTFs.missing65.mm80.nomaf.nomac.vcf.gz"

## Perform LD-pruning on the set of samples of interest
plink --allow-extra-chr --chr-set 40 --keep btfs.no_captives.pop --geno 0.1 --indep-pairwise 100 10 0.2 --out ddRAD.btfs_no_captives.mm85.tmp --set-missing-var-ids @:# --make-bed --vcf ${VCF}
plink --bfile ddRAD.btfs_cincta.mm85.tmp --allow-extra-chr --chr-set 40 --extract ddRAD.btfs_no_captives.mm85.tmp.prune.in --make-bed --out ddRAD.btfs_no_captives.mm85.100kb_LD
rm *nosex

conda activate faststructure

INPUT="ddRAD.btfs_no_captives.mm85.100kb_LD"
WORK_DIR="/mendel-nas1/dhooper/bin/miniconda3/envs/faststructure/bin"
DATE="240802"

## Run fastStructure with values of K ranging from 2 to 5
python ${WORK_DIR}/structure.py -K 2 --input ${INPUT} --cv 10 --output fastStructure/${DATE}.btfs_no_captives.mm85
python ${WORK_DIR}/structure.py -K 3 --input ${INPUT} --cv 10 --output fastStructure/${DATE}.btfs_no_captives.mm85
python ${WORK_DIR}/structure.py -K 4 --input ${INPUT} --cv 10 --output fastStructure/${DATE}.btfs_no_captives.mm85
python ${WORK_DIR}/structure.py -K 5 --input ${INPUT} --cv 10 --output fastStructure/${DATE}.btfs_no_captives.mm85
```

### FEEMS
The program [FEEMS](https://github.com/NovembreLab/feems) (Fast Estimation of Effective Migration Surfaces) uses a Gaussian Markov Random Field model to infer and visualize spatially heterogeneous isolation-by-distance patterns (i.e., effective migration rates) on a geographic surface. We generated a genetic distance matrix between samples using a set of LD-pruned SNPs, a geographic distance matrix using the longitude and latitude coordinates of each sample, and defined an outer boundary polygon using https://www.keene.edu/campus/maps/tool/.

The documentation for [FEEMS](https://github.com/NovembreLab/feems) includes a really helpful tutorial for anyone looking to get started.

See python script run_feems.220418.BTFs.py and associated input files above - listed below - for reproducing the FEEMS panel in Figure 2B.
- 220418.BTFs.miss65.mm80.feems.[bed/bim/fam] (Input genotype data in plink format]
- feems_BTFs.LTFs.miss65.mm80.samples.coord (Sample collection LONG/LAT coordinates]
- feems_BTFs.range.outer (Outer coordinates for geographic region of interest)
- world_triangle_res8.[shp/shx] (Discrete global grid)


### Fst
We evaluated the genomic landscape of differentiation between *cincta*, *atropygialis*, and *hecki* by calculating Fst between each taxon pair using [vcftools](https://vcftools.sourceforge.net) (v0.1.16). We restricted Fst analyses to the WGS dataset because it captures a far more complete representation of genomic variation than the ddRAD dataset. We first examined Fst in 20 kb sliding windows with 10 kb steps and then calculated Fst per SNP after removing singleton sites. For calculations on the Z chromosome, we restricted analysis to males to circumvent any potential issues associated with female hemizygosity.

Example window-based Fst calculations using the WGS dataset:
```
cd /mendel-nas1/dhooper/BTFs/WGS/
out_dir="/mendel-nas1/dhooper/BTFs/WGS/Fst"

## Calculate Fst in 20 kb sliding windows with 10 kb steps along autosomal genome
vcftools --gzvcf wg.btfs_ltfs.repeatmask.filter.vcf.gz --remove-filtered-all --max-missing 0.9 --not-chr chrZ --weir-fst-pop pca.pop --weir-fst-pop pah.pop --fst-window-size 20000 --fst-window-step 10000 --mac 2 --out ${out_dir}/auto.pca_pah.20kb_10kb_step
vcftools --gzvcf wg.btfs_ltfs.repeatmask.filter.vcf.gz --remove-filtered-all --max-missing 0.9 --not-chr chrZ --weir-fst-pop pcc.pop --weir-fst-pop pah.pop --fst-window-size 20000 --fst-window-step 10000 --mac 2 --out ${out_dir}/auto.pcc_pah.20kb_10kb_step
vcftools --gzvcf wg.btfs_ltfs.repeatmask.filter.vcf.gz --remove-filtered-all --max-missing 0.9 --not-chr chrZ --weir-fst-pop pca.pop --weir-fst-pop pcc.pop --fst-window-size 20000 --fst-window-step 10000 --mac 2 --out ${out_dir}/auto.pca_pcc.20kb_10kb_step

## Calculate Fst in 20 kb sliding windows with 10 kb steps along chromosome Z
vcftools --gzvcf wg.btfs_ltfs.repeatmask.filter.vcf.gz --remove-filtered-all --max-missing 0.9 --chr chrZ --weir-fst-pop pca.males.pop --weir-fst-pop pah.males.pop --fst-window-size 20000 --fst-window-step 10000 --mac 2 --out ${out_dir}/chrZ.pca_pah.20kb_10kb_step
vcftools --gzvcf wg.btfs_ltfs.repeatmask.filter.vcf.gz --remove-filtered-all --max-missing 0.9 --chr chrZ --weir-fst-pop pcc.males.pop --weir-fst-pop pah.males.pop --fst-window-size 20000 --fst-window-step 10000 --mac 2 --out ${out_dir}/chrZ.pcc_pah.20kb_10kb_step
vcftools --gzvcf wg.btfs_ltfs.repeatmask.filter.vcf.gz --remove-filtered-all --max-missing 0.9 --chr chrZ --weir-fst-pop pca.males.pop --weir-fst-pop pcc.males.pop --fst-window-size 20000 --fst-window-step 10000 --mac 2 --out ${out_dir}/chrZ.pca_pcc.20kb_10kb_step

## Combine autosomal and chrZ results into single 'whole genome' (i.e., 'wg') output
cd ${out_dir}
cat auto.pca_pah.20kb_10kb_step.windowed.weir.fst chrZ.pca_pah.20kb_10kb_step.windowed.weir.fst > wg.pca_pah.20kb_10kb_step.windowed.weir.fst
cat auto.pcc_pah.20kb_10kb_step.windowed.weir.fst chrZ.pcc_pah.20kb_10kb_step.windowed.weir.fst > wg.pcc_pah.20kb_10kb_step.windowed.weir.fst
cat auto.pca_pcc.20kb_10kb_step.windowed.weir.fst chrZ.pca_pcc.20kb_10kb_step.windowed.weir.fst > wg.pca_pcc.20kb_10kb_step.windowed.weir.fst
```

### population branch statistic (PBSn1)
We investigated subspecies specific differentiation patterns within the black-throated finch using the normalized population branch statistic (PBSn1) in 20 kb sliding windows with the long-tailed finch as outgroup. This modified version of the original PBS statistic rescales by total tree length and has been shown by [Shpak et al., 2024](https://doi.org/10.1101/2024.05.14.594139) to have a lower false positive rate in identifying local selective sweeps.

See R script plot.PBS.BTFs.R above for details about calculating the normalized population branch statistic (PBSn1) using sliding window-based Fst results.

### private alleles
We counted the number of private alleles in each taxon and sampling location using a custom perl script from [Shogren et al., 2024](https://github.com/ehshogren/MyzomelaPopulationGenomics). Private alleles were called as monomorphic or biallelic sites observed only in the focal taxon (i.e., *atropygialis*, *cincta*, or *hecki*) and present in at least five individuals. We subsequently scored each sampling location where individuals carrying that private allele were sampled. To quantify the proportion of genetic diversity unique to each sampling locality, we then calculated the proportion of private alleles found in each taxon that were also unique to each sampled population.

## heterozygosity, relatedness, and inbreeding

### observed heterozygosity
We compared genetic diversity in each of our three taxa based on the observed number of heterozygous genotypes in each sample. For the WGS dataset, we estimated mean site-based heterozygosity as the number of heterozygous genotypes on the 29 largest autosomal chromosomes divided by the summed non-repeat masked length of these chromosomes. For the ddRAD dataset, we estimated mean site-based heterozygosity as the total number of heterozygous autosomal genotypes divided by the total number of autosomal SNPs. To account for variation in missingness per sample in the ddRAD dataset, we removed 5 samples missing data at more than 20% of sites and then restricted analyses to the set of SNPs without any missing data across the remaining 251 samples. Counts of heterozygous genotypes were performed using [bcftools](http://samtools.github.io/bcftools/bcftools.html) (v1.9) without a minor allele frequency filter.

```
## Use bcftools to count the number of autosomal heterozygous sites without any missing data in the ddRAD dataset

cd /mendel-nas1/dhooper/BTFs/ddRAD/heterozygosity
out_dir="/mendel-nas1/dhooper/BTFs/ddRAD/heterozygosity/results"

## Restrict analysis to the set of 251 samples with less than 20% missing data
cat samples.miss20.list | while read LINE; do
        bcftools query -s ${LINE} -i 'GT="0|1" | GT="0/1"' -f '%CHROM:%POS\n' 240709.BTFs.LTFs.no_missing_data_autosomal.vcf.gz | wc -l > ${out_dir}/${LINE}.autosomal.het_sites.miss20.out;
done
```

See R script plot.heterozygosity.BTFs.R above for details about plotting observed heterozygosity results.

### pairwise relatedness
We examined variation in relatedness within and between our sampled populations by calculating the pairwise kinship coefficient between all samples in the ddRAD dataset using [KING](https://www.kingrelatedness.com) (v2.3.1). We defined 1st degree (kinship ≥0.18-0.35), 2nd degree (kinship ≥0.09-0.18), and 3rd degree (kinship ≥0.04-0.09) relatives based on the expected distribution of pairwise kinship coefficients for these relationships.

### runs of homozygosity
We evaluated evidence of inbreeding across populations in our sample set by contrasting the proportion of the genome observed in runs of homozygosity (i.e., FROH). We additionally evaluated the number and lengths of runs of homozygosity (ROH) across the genome as the length distribution of ROH can be especially informative about the timing of inbreeding events. We classified ROH and estimated FROH using autosomal SNPs with [plink](https://www.cog-genomics.org/plink/1.9/) (v1.09) with default parameter tuning. We did not perform LD pruning or allele frequency filtering of this dataset because of the downward-biased effect of these filters on estimates of FROH. We restricted ROH analysis to the WGS dataset because it has a marker density two orders of magnitude greater than the ddRAD dataset (WGS: 25.6 SNPs per kb; ddRAD: 0.26 SNPs per kb).

```
## Use plink to evaluate ROH in the BTF and LTF samples using the WGS dataset
## Note that we need to use the plink dataset without LD-pruning

cd /mendel-nas1/dhooper/BTFs/WGS/popgen

## Step #1: Use plink to calculate ROH
INPUT="wg.btfs_ltfs.repeatmask"

## Run with default parameter tuning
plink --bfile ${INPUT} --allow-extra-chr --chr-set 40 --not-chr chrZ --homozyg --out roh_analysis
rm *nosex
```

## demographic inference

### RAxML
We built maximum likelihood trees including all three taxa using both the WGS and ddRAD datasets with [RAxML](https://github.com/stamatak/standard-RAxML) (v8.2.4). We used [vcftools](https://vcftools.sourceforge.net) (v0.1.16) to generate a set of physically thinned SNP variants (WGS: 10 kb thinned; ddRAD: 5 kb thinned) with a minor allele count of at least two. We converted resulting VCF files to PHYLIP format using the [vcf2phylip](https://github.com/edgardomortiz/vcf2phylip) python script. For the WGS dataset, this resulted in 99,716 SNPs, 51,882 of which (those that had a minor allele in homozygosity in at least one individual) could be used for building a maximum likelihood tree. For the ddRAD dataset, this resulted in 10,632 SNPs, 6,650 could be used for maximum likelihood tree building. For both datasets, we implemented the ASC_GTRGAMMA model in combination with the Lewis correction for SNP ascertainment bias and carried out 350 bootstrap replicates. 

```
## The example below performs RAxML analysis on the ddRAD dataset
## Select input data with desired physical thinning between SNPs
thin="5k"

## Run RAxML for real with updated alignment file
raxmlHPC-PTHREADS-SSE3 -T 20 -f a -x 1001 -p 14850 -N autoMRE -m ASC_GTRGAMMA --asc-corr=lewis -s ddRAD.btfs_ltfs.raxml.${thin}_thin.filter.run.phy -n ddRAD.btfs_ltfs.raxml.${thin}_thin.tre
```

### PSMC
We used the Pairwise Sequential Markovian Coalescent [PSMC](https://github.com/lh3/psmc) model to infer historical changes in effective population sizes (Ne) in the black-throated finch and long-tailed finch. Analysis was restricted to samples with sufficient whole genome sequence data available for PSMC inference (i.e., depth of coverage ≥20×): *atropygialis*, N = 1; *cincta*, N = 1; and *hecki* N = 6. Diploid consensus sequences were generated for each sample using the [samtools](https://github.com/samtools/samtools) (v1.6) mpileup, [bcftools](http://samtools.github.io/bcftools/bcftools.html) (v1.9) call, and the ‘vcf2fq’ function from the vcfutils.pl perl script. We only considered the 29 largest autosomal chromosomes, filtered sites with a base and mapping quality below 30, a lower depth of coverage threshold of 10, and an upper depth of coverage threshold equal to twice the mean depth of coverage for each sample. Default parameters were used for PSMC module fq2psmcfa, except that we used a quality filter of 30 and a bin size of 50 bp, to account for the higher density of heterozygous sites in finches compared to humans.

```
## Prepare whole-genome diploid consensus sequence for PSMC analysis

## Set run variables and parameter tuning
ref="/mendel-nas1/dhooper/reference/GCF_003957565.2_bTaeGut1.4.fasta"
positions="/mendel-nas1/dhooper/fastq/bam/psmc/GCF_003957565.2_bTaeGut1.4.pri.positions.29_largest_autosomes.bed"
bam="BT01.merge.mkdup.bam"
runBC=`basename $bam .bam`
sample=`echo $runBC | cut -f1 -d'.'`
lower="10"
upper="110"
out_dir="/mendel-nas1/dhooper/BTFs/WGS/psmc"

## Generate consensus sequence
samtools mpileup -l ${positions} -Q 30 -q 30 -u -v -f ${ref} ${bam} | bcftools call -c | vcfutils.pl vcf2fq -d ${lower} -D ${upper} -Q 30 | gzip > ${out_dir}/${sample}.Q30.autosomal.fq.gz

## Generate psmcfa file
fq2psmcfa -s50 -q30 ${sample}.Q30.autosomal.fq.gz > ${sample}.Q30.s50.psmcfa

## Generate boostrap replicates
splitfa ${sample}.Q30.autosomal.fq.gz > ${sample}.split.psmcfa

## Run PSMC
psmc -N30 -t15 -r5 -p "2+2+25*2+4+6" -o ${sample}.Q30.s50.hilgers.psmc ${sample}.Q30.s50.psmcfa

```

### fastsimcoal
We performed demographic inference at two timescales. In the first, focused on the dynamics of black-throated finch subspecies, we modeled the demographic histories of *atropygialis* and *cincta*. In the second, focused on the dynamics within *cincta*, we modeled the demographic histories of remaining population stronghold from the Townsville Coastal Plain and the Galilee Basin. For both analyses, we used our ddRAD dataset, built two-dimension site frequency spectra (2D-SFS) using [easySFS](https://github.com/isaacovercast/easySFS), and utilized hypergeometric down projection of the allelic sample size to maximize the number of segregating sites per lineage.

```
## The example below generates 2D-SFS using the ddRAD dataset with easySFS.py
./easySFS.py -i autosomal.btfs_ltfs.no_captives.mm85.vcf.gz \
       -p pops_file.txt \
       --window-bp 1000 \
       --order hec,atr,cin \
       --proj 20,170,220 \
       -o input_sfs_data
```

We tested an initial suite of two-population models that encompassed 12 scenarios that varied in a) the timing of divergence, b) the number of distinct migration rates, c) the number and nature of population size fluctuations, and d) the size of ancestral populations. We performed 100 independent parameter runs per model using the following options: -n 100000 -L 100 -C 1 -y 5 -0 -m -q –logprecision 18 –brentol 0.0001.

```
## Select desired demographic model
#prefix="2Pop0Mig"
#prefix="2Pop0Mig1Size.A"
#prefix="2Pop0Mig1Size.C"
#prefix="2Pop0Mig2Size"
#prefix="2Pop1Mig"
#prefix="2Pop1Mig1Size.A"
#prefix="2Pop1Mig1Size.C"
#prefix="2Pop1Mig2Size"
#prefix="2Pop2Mig"
#prefix="2Pop2Mig1Size.A"
#prefix="2Pop2Mig1Size.C"
prefix="2Pop2Mig2Size"

## Use fastsimcoal2 v27 to model various demographic histories of the black-throated finch
## Perform 100 replicates
cd ${prefix}
for i in {1..100}; do
        date;
        mkdir run$i;
        cp ${prefix}.tpl ${prefix}.est ${prefix}_jointMAFpop1_0.obs run$i"/";
        cd run$i;
        fsc27093 -t ${prefix}.tpl -e ${prefix}.est -m -0 -C 1 -n 100000 -L 100 -s 0 -y 5 --logprecision 18 --brentol 0.001 -M -q -c 6 -B 6;
        cd ..;
done

```

To evaluate confidence intervals around parameter estimates under the best-fitting model, we next randomly selected sets of 20,150 SNPs (~10% of total autosomal SNPs) from the full ddRAD dataset to generate 100 non-parametric bootstrap 2D-SFS datasets using [easySFS](https://github.com/isaacovercast/easySFS). We obtained confidence intervals for parameter estimates under the best-fitting model after running a further 50 replicates per simulated dataset (i.e., for a total of 5000 parameter estimates).

Generate 100 non-parametric boostrap 2D-SFS objects:
```
folder="/mendel-nas1/dhooper/bin/easySFS"
prefix="autosomal.btfs_ltfs.no_captives.mm85"
pop_file1="pops_file_atr_cin.txt"
pop_file2="pops_file_twn_gal.txt"

bgzip -d ${prefix}.vcf.gz

bcftools view -h ${prefix}.vcf > vcf_header.txt

## Each of the resulting 100 bootstrap VCF files contains a randomly selected 20150 autosomal SNPs

for i in {1..100}; do
        cat vcf_header.txt > ${prefix}.bs$i.vcf;
        bcftools view -H ${prefix}.vcf | shuf -n 20150 | sort -k1,1 -k2,2n >> ${prefix}.bs$i.vcf;
        bgzip ${prefix}.bs$i.vcf;
        echo bs$i" ready";
done

bgzip ${prefix}.vcf

## Use easySFS.py to create an SFS file for desired populations using on autosomal SNPs

## Generate bootstrap 2D-SFS for ATR-CIN
for i in {1..100}; do
       ${folder}/easySFS.py -i ${prefix}.bs$i.vcf.gz -p ${pop_file1} --order atr,cin -a -f --proj 170,220 -o atr_cin.sfs_data.bs${i};
done

## Generate bootstrap 2D-SFS for TWN-GAL
for i in {1..100}; do
        ${folder}/easySFS.py -i ${prefix}.bs$i.vcf.gz -p ${pop_file2} --order twn,gal -a -f --proj 150,60 -o twn_gal.sfs_data.bs${i};
done
```

Perform 50 replicates for each of the 100 non-parametric bootstrap 2D-SFS to generate 95% confidince intervals under the best-fitting scenario:
```
folder="/mendel-nas1/dhooper/bin/miniconda3/envs/fastsimcoal/bin"
boot_dir="/mendel-nas1/dhooper/BTFs/ddRAD/demographics/input_data/bootstrap"
prefix="2Pop0Mig1Size.T"

for i in {1..100}; do
        date;
        mkdir bootstrap"/"${prefix}_bs$i;
        cp ${prefix}.tpl ${prefix}.est ${prefix}.pv bootstrap"/"${prefix}_bs$i"/";
        cd bootstrap"/"${prefix}_bs$i;
        cp ${boot_dir}"/"twn_gal.sfs_data.bs$i"/"fastsimcoal2"/"autosomal_jointMAFpop1_0.obs ${prefix}_jointMAFpop1_0.obs;
        for j in {1..50}; do
                mkdir run$j;
                cp ${prefix}.tpl ${prefix}.est ${prefix}.pv ${prefix}_jointMAFpop1_0.obs run$j"/";
                cd run$j"/";
                fsc27093 -t ${prefix}.tpl -e ${prefix}.est -m -0 -C 1 -n 150000 -L 100 -s 0 -y 5 --logprecision 18 --brentol 0.001 -M --initvalues ${prefix}.pv -q -c 6 -B 6;
                cd ..;
        done
        cd ../..;
done
```
